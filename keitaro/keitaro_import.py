#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ò–º–ø–æ—Ä—Ç –æ—Ñ—Ñ–µ—Ä–æ–≤ –∏–ª–∏ –ª–µ–Ω–¥–∏–Ω–≥–æ–≤ –≤ Keitaro –∏–∑ —Ä–∞–Ω–µ–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞—Ä—Ö–∏–≤–æ–≤.
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ—Ç –≥—Ä—É–ø–ø—ã –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç, –∑–∞–≥—Ä—É–∂–∞–µ—Ç ZIP-–∞—Ä—Ö–∏–≤—ã.
–†–∞–±–æ—Ç–∞–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∫—Ä–∏–ø—Ç–∞ keitaro_universal_export.py


# Keitaro API –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞)
KEITARO_TRACKER_URL=https://your-tracker-domain.com
KEITARO_API_KEY=your-api-key-here

# Keitaro API –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (—Ü–µ–ª—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞)
KEITARO_TARGET_URL=https://your-target-tracker-domain.com
KEITARO_TARGET_API_KEY=your-target-api-key-here

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏–º–ø–æ—Ä—Ç—É:
1. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ .env —Ñ–∞–π–ª:
# –¶–µ–ª–µ–≤–æ–π —Ç—Ä–µ–∫–µ—Ä (–∫—É–¥–∞ –∑–∞–≥—Ä—É–∂–∞—Ç—å)
KEITARO_TARGET_URL=https://your-new-tracker.com
KEITARO_TARGET_API_KEY=your-new-api-key

2. –í —Å–∫—Ä–∏–ø—Ç–µ keitaro_import.py —É–∫–∞–∂–∏—Ç–µ:
CONFIG = {
    # ...
    "IMPORT_TYPE": "offers",  # –∏–ª–∏ "landings"
    "IMPORT_DIR": "–ø—É—Ç—å_–∫_–≤–∞—à–µ–π_–ø–∞–ø–∫–µ",  # –Ω–∞–ø—Ä–∏–º–µ—Ä: "offer_exports_20250104"
    # ...
}

3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∏–º–ø–æ—Ä—Ç:
python3 keitaro_import.py

–ß—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç:
‚úÖ –°–∫—Ä–∏–ø—Ç –ø—Ä–æ—á–∏—Ç–∞–µ—Ç index.csv –∏–∑ –≤–∞—à–µ–π –ø–∞–ø–∫–∏

‚úÖ –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ—Ñ—Ñ–µ—Ä–∞/–ª–µ–Ω–¥–∏–Ω–≥–∞:

–ü—Ä–æ–≤–µ—Ä–∏—Ç, –µ—Å—Ç—å –ª–∏ –≥—Ä—É–ø–ø–∞ —Å —Ç–∞–∫–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º
–ï—Å–ª–∏ –Ω–µ—Ç - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—Å—Ç –≥—Ä—É–ø–ø—É
–ó–∞–≥—Ä—É–∑–∏—Ç ZIP-–∞—Ä—Ö–∏–≤ —á–µ—Ä–µ–∑ /import —ç–Ω–¥–ø–æ–∏–Ω—Ç
–ü—Ä–∏–≤—è–∂–µ—Ç –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –≥—Ä—É–ø–ø–µ
‚úÖ –í –∫–æ–Ω—Ü–µ –ø–æ–∫–∞–∂–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É:

–°–∫–æ–ª—å–∫–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ
–°–∫–æ–ª—å–∫–æ –ø—Ä–æ–ø—É—â–µ–Ω–æ (–µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å)
–û—à–∏–±–∫–∏ (–µ—Å–ª–∏ –±—ã–ª–∏)
–ù–∞—Å—Ç—Ä–æ–π–∫–∏:
CREATE_GROUPS: True - —Å–æ–∑–¥–∞–≤–∞—Ç—å –≥—Ä—É–ø–ø—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ ‚úÖ
SKIP_EXISTING: True - –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º
MATCH_BY_NAME: True - —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—Ç—å –ø–æ –∏–º–µ–Ω–∞–º
–°–∫—Ä–∏–ø—Ç —É–∂–µ –≤—Å—ë —É—á–∏—Ç—ã–≤–∞–µ—Ç! –ü—Ä–æ—Å—Ç–æ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —ç–∫—Å–ø–æ—Ä—Ç–æ–º –∏ –∑–∞–ø—É—Å–∫–∞–π—Ç–µ üöÄ


"""

import os
import csv
import json
import time
import requests
from datetime import datetime
from pathlib import Path

# ======================== CONFIG ========================
CONFIG = {
    "BASE_URL": None,  # –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ .env
    "API_KEY": None,   # –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ .env

    # ========== –ù–ê–°–¢–†–û–ô–ö–ò –ò–ú–ü–û–†–¢–ê ==========
    "IMPORT_TYPE": "offers",  # "offers" –∏–ª–∏ "landings"
    "IMPORT_DIR": None,  # –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —ç–∫—Å–ø–æ—Ä—Ç–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä: "offer_exports_20250103_123456")
    # =======================================

    "TIMEOUT": 90,
    "SLEEP_BETWEEN": 0.3,  # —Å–µ–∫ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    "CREATE_GROUPS": True,  # —Å–æ–∑–¥–∞–≤–∞—Ç—å –≥—Ä—É–ø–ø—ã –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    "SKIP_EXISTING": True,  # –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º
}
# ====================== /CONFIG ========================


def load_config_from_env():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ .env —Ñ–∞–π–ª–∞"""
    try:
        from dotenv import load_dotenv
        load_dotenv()
        CONFIG["BASE_URL"] = os.getenv("KEITARO_TARGET_URL") or os.getenv("KEITARO_TRACKER_URL")
        CONFIG["API_KEY"] = os.getenv("KEITARO_TARGET_API_KEY") or os.getenv("KEITARO_API_KEY")
    except ImportError:
        print("[WARNING] dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")


def _session(api_key: str) -> requests.Session:
    s = requests.Session()
    s.headers.update(
        {
            "Api-Key": api_key,
            "Accept": "application/json",
        }
    )
    return s


def _api(base: str, path: str) -> str:
    base = base.rstrip("/")
    path = path.lstrip("/")
    return f"{base}/admin_api/v1/{path}"


def detect_landings_endpoint(
    s: requests.Session, base: str, timeout: int
) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ª–µ–Ω–¥–∏–Ω–≥–æ–≤"""
    for ep in ("landing_pages", "landings"):
        url = _api(base, f"{ep}?per_page=1")
        try:
            r = s.get(url, timeout=timeout)
            if r.status_code == 200:
                return ep
        except requests.RequestException:
            pass
    raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —ç–Ω–¥–ø–æ–∏–Ω—Ç –ª–µ–Ω–¥–∏–Ω–≥–æ–≤")


def get_all_groups(s: requests.Session, base: str, timeout: int) -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {name: id}"""
    groups = {}
    try:
        url = _api(base, "groups?per_page=500")
        r = s.get(url, timeout=timeout)
        r.raise_for_status()
        data = r.json()
        items = data.get("data") if isinstance(data, dict) else data
        if items:
            for g in items:
                name = g.get("name") or g.get("title") or ""
                if name:
                    groups[name] = g.get("id")
    except requests.RequestException as e:
        print(f"[WARNING] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø: {e}")
    return groups


def create_group(s: requests.Session, base: str, group_name: str, timeout: int) -> int | None:
    """–°–æ–∑–¥–∞—Ç—å –≥—Ä—É–ø–ø—É. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç ID –≥—Ä—É–ø–ø—ã"""
    try:
        url = _api(base, "groups")
        payload = {"name": group_name}
        r = s.post(url, json=payload, timeout=timeout)
        r.raise_for_status()
        data = r.json()
        group_id = data.get("id")
        print(f"    ‚úì –°–æ–∑–¥–∞–Ω–∞ –≥—Ä—É–ø–ø–∞: {group_name} (ID: {group_id})")
        return group_id
    except requests.RequestException as e:
        print(f"    ‚úó –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä—É–ø–ø—É '{group_name}': {e}")
        return None


def get_existing_items(
    s: requests.Session, base: str, endpoint: str, timeout: int
) -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {name: id}"""
    items = {}
    page = 1
    per_page = 200
    while True:
        try:
            url = _api(base, f"{endpoint}?per_page={per_page}&page={page}")
            r = s.get(url, timeout=timeout)
            r.raise_for_status()
            data = r.json()
            entries = data.get("data") if isinstance(data, dict) else data
            if not entries:
                break
            for item in entries:
                name = item.get("name") or ""
                if name:
                    items[name] = item.get("id")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
            total_pages = None
            if isinstance(data, dict):
                meta = data.get("meta") or {}
                pagination = meta.get("pagination") or {}
                total_pages = pagination.get("total_pages")
            if not total_pages or page >= int(total_pages):
                break
            page += 1
        except requests.RequestException:
            break
    return items


def upload_zip(
    s: requests.Session,
    base: str,
    endpoint: str,
    zip_path: str,
    name: str,
    group_id: int | None,
    timeout: int,
) -> dict | None:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å ZIP-–∞—Ä—Ö–∏–≤"""
    try:
        url = _api(base, f"{endpoint}/import")

        with open(zip_path, "rb") as f:
            files = {"file": (os.path.basename(zip_path), f, "application/zip")}
            data = {"name": name}
            if group_id:
                data["group_id"] = group_id

            r = s.post(url, files=files, data=data, timeout=timeout)
            r.raise_for_status()
            return r.json()
    except requests.RequestException as e:
        print(f"    ‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ZIP: {e}")
        return None


def create_from_json(
    s: requests.Session,
    base: str,
    endpoint: str,
    json_data: dict,
    name: str,
    group_id: int | None,
    timeout: int,
) -> dict | None:
    """–°–æ–∑–¥–∞—Ç—å —ç–ª–µ–º–µ–Ω—Ç –∏–∑ JSON –¥–∞–Ω–Ω—ã—Ö"""
    try:
        url = _api(base, endpoint)

        # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
        payload = {
            "name": name,
        }

        if group_id:
            payload["group_id"] = group_id

        # –ö–æ–ø–∏—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ –ø–æ–ª—è –∏–∑ JSON
        important_fields = [
            "archive_type",
            "state",
            "country",
            "action_type",
            "action_payload",
            "action_options",
            "notes",
        ]

        for field in important_fields:
            if field in json_data and json_data[field] is not None:
                payload[field] = json_data[field]

        r = s.post(url, json=payload, timeout=timeout)
        r.raise_for_status()
        return r.json()
    except requests.RequestException as e:
        print(f"    ‚úó –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–∑ JSON: {e}")
        return None


def main():
    load_config_from_env()

    base = CONFIG["BASE_URL"]
    api_key = CONFIG["API_KEY"]
    import_type = CONFIG["IMPORT_TYPE"].lower()
    import_dir = CONFIG["IMPORT_DIR"]

    if not base or not api_key:
        print("‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–∫–∞–∑–∞–Ω—ã KEITARO_TARGET_URL –∏ KEITARO_TARGET_API_KEY –≤ .env")
        print("   –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ KEITARO_TRACKER_URL –∏ KEITARO_API_KEY")
        return

    if import_type not in ("offers", "landings"):
        print(f"‚ùå –û–®–ò–ë–ö–ê: IMPORT_TYPE –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'offers' –∏–ª–∏ 'landings'")
        return

    if not import_dir:
        print("‚ùå –û–®–ò–ë–ö–ê: –£–∫–∞–∂–∏—Ç–µ IMPORT_DIR - –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —ç–∫—Å–ø–æ—Ä—Ç–æ–º")
        return

    if not os.path.isdir(import_dir):
        print(f"‚ùå –û–®–ò–ë–ö–ê: –ü–∞–ø–∫–∞ '{import_dir}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º index.csv
    index_file = os.path.join(import_dir, "index.csv")
    if not os.path.isfile(index_file):
        print(f"‚ùå –û–®–ò–ë–ö–ê: –§–∞–π–ª '{index_file}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return

    timeout = CONFIG["TIMEOUT"]
    s = _session(api_key)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç
    if import_type == "landings":
        endpoint = detect_landings_endpoint(s, base, timeout)
        item_type_ru = "–ª–µ–Ω–¥–∏–Ω–≥"
    else:
        endpoint = "offers"
        item_type_ru = "–æ—Ñ—Ñ–µ—Ä"

    print(f"[INFO] –†–µ–∂–∏–º –∏–º–ø–æ—Ä—Ç–∞: {import_type.upper()}")
    print(f"[INFO] –≠–Ω–¥–ø–æ–∏–Ω—Ç: {endpoint}")
    print(f"[INFO] –¶–µ–ª–µ–≤–æ–π —Ç—Ä–µ–∫–µ—Ä: {base}")
    print(f"[INFO] –ü–∞–ø–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {import_dir}")
    print()

    # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≥—Ä—É–ø–ø—ã
    print("[1/4] –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≥—Ä—É–ø–ø...")
    groups_map = get_all_groups(s, base, timeout)
    print(f"    –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø: {len(groups_map)}")

    # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
    if CONFIG["SKIP_EXISTING"]:
        print(f"[2/4] –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö {import_type}...")
        existing_items = get_existing_items(s, base, endpoint, timeout)
        print(f"    –ù–∞–π–¥–µ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö: {len(existing_items)}")
    else:
        existing_items = {}
        print("[2/4] –ü—Ä–æ–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö (SKIP_EXISTING=False)")

    # –ß–∏—Ç–∞–µ–º index.csv
    print("[3/4] –ß—Ç–µ–Ω–∏–µ index.csv...")
    items_to_import = []
    with open(index_file, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            items_to_import.append(row)
    print(f"    –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(items_to_import)}")

    # –ò–º–ø–æ—Ä—Ç
    print(f"[4/4] –ù–∞—á–∏–Ω–∞–µ–º –∏–º–ø–æ—Ä—Ç...")
    print()

    total = 0
    success = 0
    skipped = 0
    failed_list = []

    for item in items_to_import:
        total += 1
        item_id = item.get("id")
        name = item.get("name")
        group_name = item.get("group")
        file_path = item.get("file_path")
        file_type = item.get("type")

        print(f"[{total}/{len(items_to_import)}] {item_type_ru.capitalize()}: {name}")

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å
        if CONFIG["SKIP_EXISTING"] and name in existing_items:
            print(f"    ‚äò –ü—Ä–æ–ø—É—â–µ–Ω (—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)")
            skipped += 1
            time.sleep(CONFIG["SLEEP_BETWEEN"])
            continue

        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –≥—Ä—É–ø–ø—É
        group_id = None
        if group_name and group_name != CONFIG.get("GROUP_UNGROUPED", "__NO_GROUP__"):
            if group_name in groups_map:
                group_id = groups_map[group_name]
            elif CONFIG["CREATE_GROUPS"]:
                group_id = create_group(s, base, group_name, timeout)
                if group_id:
                    groups_map[group_name] = group_id

        # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        full_path = os.path.join(import_dir, file_path)

        if not os.path.isfile(full_path):
            print(f"    ‚úó –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {full_path}")
            failed_list.append(
                {"id": item_id, "name": name, "reason": "file_not_found"}
            )
            continue

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º
        result = None
        if file_type == "zip":
            print(f"    ‚Üí –ó–∞–≥—Ä—É–∑–∫–∞ ZIP...")
            result = upload_zip(s, base, endpoint, full_path, name, group_id, timeout)
        elif file_type == "json":
            print(f"    ‚Üí –°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ JSON...")
            with open(full_path, "r", encoding="utf-8") as f:
                json_data = json.load(f)
            result = create_from_json(
                s, base, endpoint, json_data, name, group_id, timeout
            )

        if result:
            success += 1
            result_id = result.get("id")
            print(f"    ‚úì –£—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω (ID: {result_id})")
        else:
            failed_list.append(
                {"id": item_id, "name": name, "reason": "import_failed"}
            )

        time.sleep(CONFIG["SLEEP_BETWEEN"])

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –æ–± –æ—à–∏–±–∫–∞—Ö
    if failed_list:
        failed_file = os.path.join(import_dir, "import_failed.json")
        with open(failed_file, "w", encoding="utf-8") as f:
            json.dump(failed_list, f, ensure_ascii=False, indent=2)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 60)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–ú–ü–û–†–¢–ê")
    print("=" * 60)
    print(f"–¢–∏–ø –∏–º–ø–æ—Ä—Ç–∞:          {import_type.upper()}")
    print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:        {total}")
    print(f"–£—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {success}")
    print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ (–µ—Å—Ç—å):     {skipped}")
    print(f"–û—à–∏–±–æ–∫:               {len(failed_list)}")
    if failed_list:
        print(f"\n–û—à–∏–±–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:     {os.path.join(import_dir, 'import_failed.json')}")
    print("=" * 60)


if __name__ == "__main__":
    main()
